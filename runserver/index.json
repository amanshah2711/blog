[{"content":"Introduction The purpose of this note is to give a rudimentary and perspicuous presentation of some foundational topics in linear algebra. There will be an emphasis on geometric intuition and connecting various ideas that are often presented in isolation. The requisite knowledge required is familiarity with rank-nullity and hyperplanes.\nMathematical Preliminaries Let $U,W$ be two subspaces of a vector space $V$. One notion we will need is the vector space joined by combining $U$ and $V$. To be precise we mean the following.\nDefinition: The sum of two vector spaces $U,W \\subset V$ is defined as the set, $U+W$, of all linear combinations that can be made from vectors in $U \\cup W$.\nWe note that $U+W$ is a subspace of $V$ as it contains $0$ and is closed under linear combinations. Two important examples are as follows.\nExample 1: First define the $x$-axis as the set, $X:=\\{(x,y) \\in \\mathbf{R}^2 : y = 0\\}$. Now the sum of $\\mathbf{R}^2$ with the $x$-axis, $\\mathbf{R}^2 + X$, is simply the entire plane $\\mathbf{R}^2$. Here we note nothing was gained by adding $X$.\nExample 2: First define the $x$-axis as the set, $X:=\\{(x,y) \\in \\mathbf{R}^2 : y = 0\\}$ and the $y$-axis as the set, $Y:=\\{(x,y) \\in \\mathbf{R}^2 : x = 0\\}$. Now observe that the sum of the $x$ and $y$ axes, $X+Y$, is the entire plane as one would expect. For full generality it is essential to remember that we can take sums of axes that are not perpendicular.\nClearly certain sums are more useful than others in their ability to \u0026ldquo;add\u0026rdquo; more vectors as occurred in Example 2. To distinguish these special sums we define the following.\nDefinition: $U+W$ is called a direct sum if every element in $U+W$ has a unique representation as the sum of an element in $U$ and an element in $W$. That is $\\mathbf{z} \\in U+W$ has unique representation $\\mathbf{z}=\\mathbf{u}+\\mathbf{w}$ where $\\mathbf{u} \\in U$ and $\\mathbf{w} \\in W$.\nWe note that the two above definitions allow us to add multiple subspaces together so statements such as $U_1+U_2+U_3$ are well-defined. In addition, the notion of direct sum in for multiple subspaces extends in the obvious way to mean unique representation as the sum of elements from each subspace.\nProjectors With the preliminaries done we can now define special kind of map known as a projector.\nDefinition: Given some direct sum $U+W = V$, we define a projector, $\\mathbf{P}: V \\to V$ as follows. Since $U+W = V$ we have any $\\mathbf{v} \\in V$ has unique representation as $\\mathbf{v} = \\mathbf{u} + \\mathbf{w}$ for some choice of $\\mathbf{u} \\in U$ and $\\mathbf{w} \\in W$. With this we define $\\mathbf{Pv} := \\mathbf{u}$.\nExercise: Prove that a projector is linear.\nExample 3: Consider the direct sum $X+Y$ from Example 2. We can define a projector that maps elements to the $X$ or $Y$ axis. This coincides with what we typically think of as projections.\nWe should point out that we can also project onto the axis of a non-perpendicular grid on the plane as well. Such an operation would also be a projector. In fact this general notion is the one to keep in mind going forward.\nRelation to Idempotence We say a function, $f$, is idempotent if $f \\circ f = f$. That is if applying the function twice is the same as applying it once. There are many examples such as the identity function or absolute value function on the real numbers.\nNow our definition of projections makes it simple to construct a projection given a direct sum. However, it may not be obvious if a given linear operator is a projection. It turns out there is a simple test to determine if a given linear operator, $\\mathbf{P}$, is a projection.\nTheorem: A linear operator, $\\mathbf{P}$, is a projection if and only if $\\mathbf{P}^2 = \\mathbf{P}$. That is $\\mathbf{P}$ is idempotent.\nWe remark that the absolute value function is not a linear map on $\\mathbf{R}$ but is idempotent. This does not contradict the above theorem because the above theorem states that any linear, idempotent operator is a projector.\nThis theorem will enable us to quickly check if an operator is a projection in later sections.\nProjection to Lines Physical Example Consider a sunny day and a lamp post standing erect on perfectly flat ground. Since the sun is sufficiently far away we assume the rays of light are parallel. The lamp post has a shadow as long as these rays of light are not parallel or perpendicular to the lamp post. The height of the shadow is determined by looking at the ray that intersects the top of the lamp post and advecting the top of the post to the ground along this ray. The advection of this point to the ground is an example of a non-orthogonal1 projector. Linear algebra is a suitable medium for modeling this phenomena as we shall soon see. Figure 1: Picture of the top of the lamp post being advected to the tip of the shadow along the ray of light (depicted in black) that intersects the top of the post.\nElementary Projectors In general, we define an elementary projector using two objects: a given real-valued linear function $\\mathbf{f}^T$, and a given vector $\\mathbf{r}$. The projection of a point $\\mathbf{z}$ is then defined in the following manner. Consider the point $\\mathbf{z}$ and the hyperplane defined by $\\mathbf{f}^T$ that it lies on. Then look at the point formed by the intersection of the foregoing hyperplane with $\\text{span}{\\mathbf{r}}$. This point of intersection is defined as the elementary projection of $\\mathbf{z}$ onto $\\text{span}{\\mathbf{r}}$ given $\\mathbf{f}^T$. This process can be viewed as advecting $\\mathbf{z}$ along the line segment connecting it to $\\text{span}{\\mathbf{r}}$ which lies wholly in a level set of $\\mathbf{f}^T$.\nIn our physical analogy level sets of $\\mathbf{f}^T$ correspond to rays of light and the floor corresponds to $\\text{span} {\\mathbf{r}}$.\nWe deduce a mathematical formula by exploiting two critical facts: the projection is equal to $\\lambda \\mathbf{r}$ for appropriate scalar $\\lambda$, and the projection and $\\mathbf{z}$ lie in the same level set of $\\mathbf{f}^T$. Thus $\\lambda = \\frac{\\mathbf{f}^{T}\\mathbf{z}}{\\mathbf{f}^T\\mathbf{r}}$. Therefore our resulting projection is,\n$$\\frac{\\mathbf{r}\\mathbf{f}^{T}}{\\mathbf{f}^T\\mathbf{r}} \\mathbf{z}.$$\nWe note in our derivation we assumed that $\\mathbf{f}^{T}$ intersects $\\mathbf{r}$ at a unique point. This is equivalent to assuming $\\mathbf{f}^{T}\\mathbf{r} \\neq 0$ which makes our expression well defined. Given the derivation we can summarize our findings with the following.\nDefinition: We say an operator $\\mathbf{P}$ is an elementary projector if $\\mathbf{P} = \\frac{\\mathbf{r}\\mathbf{f}^{T}}{\\mathbf{f}^T\\mathbf{r}}$.\nWe can verify this is in fact a projector by calculating $\\mathbf{P}^2$ and observing the $\\mathbf{P}$ is idempotent. Thus our elementary projector is a projector as expected.\nWe note an equivalent definition of elementary projector is the following.\nDefinition: Given a direct sum $U+W = V$, we define a projector $\\mathbf{P}$ exactly as before. If $U$ is one dimensional then we call $\\mathbf{P}$ an elementary projector.\nBoth definitions of an elementary projector are equivalent, however the first gives us a formula and method to compute an elementary projector. For clarity and completeness we demonstrate a proof that these are equivalent.\nTheorem: Every projector, $\\mathbf{P}$, onto a one dimensional subspace can be written as $\\frac{\\mathbf{r}\\mathbf{f}^{T}}{\\mathbf{f}^T\\mathbf{r}}$\nElementary Orthogonal Projections It is common to restrict discussion of elementary projections to those that are orthogonal. That is the level sets of $\\mathbf{r}^T$ are perpendicular to $\\mathbf{c}$. If our coordinate system consists of basis of orthonormal vectors(as is almost always the case in applications) then the transpose of $c$ is the appropriate choice of $\\mathbf{r}^T$. This process corresponds to projection of a point onto a line in a coordinate system consisting of straight, perpendicular axes such as the Cartesian plane. Think \u0026ldquo;dropping a perpendicular\u0026rdquo;.\nExample 1: $2 \\times 2$ Matrix Inverse Given a matrix, $$ M = \\begin{bmatrix}a \u0026amp; b \\newline c \u0026amp; d\\end{bmatrix} = \\begin{bmatrix} \\vert \u0026amp; \\vert \\newline p \u0026amp; q \\newline \\vert \u0026amp; \\vert \\end{bmatrix}, $$ it is well-known that the inverse matrix is, $$ M^{-1} = \\frac{1}{ad-bc}\\begin{bmatrix}d \u0026amp; -b \\newline -c \u0026amp; a\\end{bmatrix}. $$ Figure 1: The orange and green lines correspond to the $p$ and $q$ axes, respectively. Their intersection is the origin and the light blue point denotes the projection onto $\\text{span }p$\nViewing the matrix, $M$, as a change of coordinates leads to a perspicuous derivation of the inverse. $M$ takes coordinates from the $pq$ grid and changes them to coordinates of the $xy$ grid. Hence, the inverse should be the matrix that transforms $xy$ coordinates $pq$ coordinates. Moving a point written in $xy$ coordinates onto the line $\\text{span }p$ geometrically corresponds to translating the point along lines parallel to $\\text{span }q$ until it intersects $\\text{span }p$. This is exactly an elementary projection where $r = p$ and $f^T$ has level sets parallel to $\\text{span }q$. To determine $f^T$ precisely can be identified with a $1 \\times 2$ matrix that sends $\\text{span } q$ to $0$. One can arrive at $f^T = \\begin{bmatrix} d \u0026amp; -b\\end{bmatrix}$ by guessing or by rotating $q$ ninety degrees counterclockwise . Thus we conclude, $$ \\frac{f^{T}}{f^Tr} = \\frac{1}{ad-bc} \\begin{bmatrix} d \u0026amp; -b \\end{bmatrix}, $$ is the operator we need to apply to $xy$ coordinates to find the $p$-coordinate in our $pq$ grid. This is exactly the first row of our inverse matrix above. The second row can be derived using the same methodology as above except interchanging the role of $p$ and $q$.\nThis method generalizes to higher dimensions so we can understand how to geometrically derive inverses of matrices in all cases. However, it becomes tricky to determine $\\mathbf{f}^T$ in higher dimensions. The cleanest method would be to use the determinant to derive the appropriate $\\mathbf{f}^T$. Do you see how? This should also give complete geometric meaning to the adjugate matrix which is typically defined using cofactors and algebraic chicanery that obscures its geometric essence.\nExample 2: Stereographic Projection Stereographic projection is a mapping from the unit sphere in 3d space to the $xy$ plane that often arises in complex analysis. The mapping is defined as follows. For any point on the sphere draw the line intersecting the north pole and the foregoing sphere; the intersection of this line and the $xy$ plane is stereographic projection of the point. The north pole is the only point on the sphere for which we cannot define its stereographic projection. If we restrict to only looking at the plane containing the origin, $P$, and $N$ we see this operation can be described by an elementary projector. Let $\\mathbf{r}$ correspond to horizontal axis and let $\\mathbf{f}^T$ have level sets parallel to the line between the North Pole and $P$. That is use the North Pole and $P$ to deduce $\\mathbf{f}^T$. The elementary projector is determined one can deduce the $x$ and $y$ components in the plane using basic trigonometry.\nProjections to Vector Spaces Big Theorem: Decomposition Up until now we have only considered the simplest projectors and basic applications. A generic projector can have $\\text{dim }U \u0026gt; 1$. These may seem more complicated however we have the following decomposition.\nTheorem: Every projector $\\mathbf{P}$ can be decomposed into a sum of pairwise, mutually annihilating elementary projectors. That is $\\mathbf{P} = \\mathbf{P}_1 + \\mathbf{P_2} + \\ldots + \\mathbf{P}_m$ where $\\mathbf{P}_i\\mathbf{P}_j = 0$ if $i \\neq j$.\nLet $U + W = V$ be the direct sum such that $\\mathbf{P}\\mathbf{z} = \\mathbf{P}(\\mathbf{u}+\\mathbf{w}) = \\mathbf{u}$ where $\\mathbf{u} \\in U$ and $\\mathbf{w} \\in W$. Consider $\\mathbf{u}_1, \\mathbf{u}_2, \\ldots, \\mathbf{u}_m$ to be a basis for $U$. Then given the direct sum $\\text{span } \\mathbf{u}_i + (( \\cup_{j \\neq i} \\mathbf{u}_j ) \\cup W )$ define the elementary projector, $\\mathbf{P}_i$, which maps onto $\\text{span }\\mathbf{u}_i $. From our definitions we have that $\\mathbf{P} = \\mathbf{P}_1 + \\ldots + \\mathbf{P}_m$. The various $\\mathbf{P}_i$ are also mutually annihilating(i.e. $\\mathbf{P}_i\\mathbf{P}_j = 0$ if $ i \\neq j$) which is easily verified.\nExample 1: Least Squares Example 2: Quantum Mechanics Example 3: Cross Products Connection to Spectral Theory Been boop\nConnection to Optimization We are often in situations where we are given a norm. That is we are given a way to measure lengths in the space. Many optimization problems consist of\nReflectors We will mimic the development done for projectors to develop the theory of reflectors.\nDefinition: Given some direct sum $U+W = V$, we define a reflector, $\\mathbf{R}: V \\to V$ as follows. Since $U+W = V$ we have any $\\mathbf{v} \\in V$ has unique representation as $\\mathbf{v} = \\mathbf{u} + \\mathbf{w}$ for some choice of $\\mathbf{u} \\in U$ and $\\mathbf{w} \\in W$. With this we define $\\mathbf{Rv} := \\mathbf{u} - \\mathbf{w}$.\nExercise: Prove that a reflector is linear.\nExample 3: Consider the direct sum $X+Y$ from Example 2. We can define a reflector that reflects over the $X$ or $Y$ axis. This coincides with what we typically think of as reflection.\nRelation to Projections It turns out reflectors and projectors are intimately related. When we reflect a point in the plane over the $x$-axis, we could explicitly do this in 2 steps. We could first project the point onto the $y$-axis. Then we subtract twice the projection onto the $y$-axis from the original point. It turns out this method using projectors to build reflectors is more general. We sum this up as follows.\nTheorem: Every reflector $\\mathbf{R}$ can be expressed $\\mathbf{R} = \\mathbf{I} - 2\\mathbf{P}$ where $\\mathbf{P}$ is some appropriate choice of projector.\nGiven the direct sum $U+W$ corresponding to the reflector $\\mathbf{R}$ we define the projector $\\mathbf{P}_W \\mathbf{z} = \\mathbf{P}_W (\\mathbf{u} + \\mathbf{w}) = \\mathbf{w}$. From this it follows that $\\mathbf{R} = \\mathbf{I} - 2\\mathbf{P}_W$.\nRelation to Involution We say a function, $f$, is an involution if $(f \\circ f)(x) = x$. That is if applying the function twice is the same as applying the identity. There are many examples such as taking reciprocals, multiplying by $-1$, or complex conjugation.\nNow our definition of reflectors makes it simple to construct a reflector given a direct sum. However, it may not be obvious if a given linear operator is a reflector. It turns out there is a simple test to determine if a given linear operator, $\\mathbf{R}$, is a reflector.\nTheorem: A linear operator, $\\mathbf{R}$, is a reflector if and only if $\\mathbf{R}^2 = \\mathbf{I}$. That is $\\mathbf{R}$ is involution.\nProving the necessity of involution is a straightforward exercise. Do you see why? However proving that if a linear operator, $\\mathbf{R}$ satisfies $\\mathbf{R}^2 = \\mathbf{I}$ then it is a reflection is more difficult. We invoke the relation to projection to note\nReflection Over Hyperplanes Physical Example Elementary Reflectors Elementary Orthogonal Reflectors (Householder Transformations) Complex Conjugation Reflection Over Subspaces Big Theorem: Decomposition Dilators Elementary Dilator When Is An Operator A Dilator? Gaussian Elimination Non-orthogonal refers to the fact that the ray connecting the tips of the shadow and post does not form a right angle with the ground.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://amanshah2711.github.io/paper-blog/posts/projections/","summary":"Introduction The purpose of this note is to give a rudimentary and perspicuous presentation of some foundational topics in linear algebra. There will be an emphasis on geometric intuition and connecting various ideas that are often presented in isolation. The requisite knowledge required is familiarity with rank-nullity and hyperplanes.\nMathematical Preliminaries Let $U,W$ be two subspaces of a vector space $V$. One notion we will need is the vector space joined by combining $U$ and $V$.","title":"Geometry of Linear Operators"}]