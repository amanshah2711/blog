<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Geometry of Linear Operators | Parallelogram</title><meta name=keywords content><meta name=description content="Introduction The purpose of this note is to give a rudimentary and perspicuous presentation of some foundational topics in linear algebra. There will be an emphasis on geometric intuition and connecting various ideas that are often presented in isolation. The requisite knowledge required is familiarity with rank-nullity and hyperplanes.
Mathematical Preliminaries Let $U,W$ be two subspaces of a vector space $V$. One notion we will need is the vector space joined by combining $U$ and $V$."><meta name=author content="Aman Shah"><link rel=canonical href=https://amanshah2711.github.io/paper-blog/posts/projections/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/paper-blog/assets/css/stylesheet.6a98292fb8fa8cf0f3ba4042d4b75515c04267550f3ad49ff6271b5af9562443.css integrity="sha256-apgpL7j6jPDzukBC1LdVFcBCZ1UPOtSf9icbWvlWJEM=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/paper-blog/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://amanshah2711.github.io/paper-blog/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=https://amanshah2711.github.io/paper-blog/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://amanshah2711.github.io/paper-blog/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://amanshah2711.github.io/paper-blog/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://amanshah2711.github.io/paper-blog/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css integrity=sha384-vKruj+a13U8yHIkAyGgK1J3ArTLzrFGBbBc0tDp4ad/EyewESeXE/Iv67Aj8gKZ0 crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.js integrity=sha384-PwRUT/YqbnEjkZO0zZxNqcxACrXe+j766U2amXcgMg5457rve2Y7I6ZJSm2A0mS4 crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous onload=renderMathInElement(document.body)></script>
<script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}]})})</script><script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(e,t,n,s,o,i,a){e.GoogleAnalyticsObject=o,e[o]=e[o]||function(){(e[o].q=e[o].q||[]).push(arguments)},e[o].l=1*new Date,i=t.createElement(n),a=t.getElementsByTagName(n)[0],i.async=1,i.src=s,a.parentNode.insertBefore(i,a)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-123-45","auto"),ga("send","pageview"))</script><meta property="og:title" content="Geometry of Linear Operators"><meta property="og:description" content="Introduction The purpose of this note is to give a rudimentary and perspicuous presentation of some foundational topics in linear algebra. There will be an emphasis on geometric intuition and connecting various ideas that are often presented in isolation. The requisite knowledge required is familiarity with rank-nullity and hyperplanes.
Mathematical Preliminaries Let $U,W$ be two subspaces of a vector space $V$. One notion we will need is the vector space joined by combining $U$ and $V$."><meta property="og:type" content="article"><meta property="og:url" content="https://amanshah2711.github.io/paper-blog/posts/projections/"><meta property="og:image" content="https://amanshah2711.github.io/paper-blog/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-03-09T00:00:00+00:00"><meta property="article:modified_time" content="2023-03-09T00:00:00+00:00"><meta property="og:site_name" content="Parallelogram"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://amanshah2711.github.io/paper-blog/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Geometry of Linear Operators"><meta name=twitter:description content="Introduction The purpose of this note is to give a rudimentary and perspicuous presentation of some foundational topics in linear algebra. There will be an emphasis on geometric intuition and connecting various ideas that are often presented in isolation. The requisite knowledge required is familiarity with rank-nullity and hyperplanes.
Mathematical Preliminaries Let $U,W$ be two subspaces of a vector space $V$. One notion we will need is the vector space joined by combining $U$ and $V$."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://amanshah2711.github.io/paper-blog/posts/"},{"@type":"ListItem","position":2,"name":"Geometry of Linear Operators","item":"https://amanshah2711.github.io/paper-blog/posts/projections/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Geometry of Linear Operators","name":"Geometry of Linear Operators","description":"Introduction The purpose of this note is to give a rudimentary and perspicuous presentation of some foundational topics in linear algebra. There will be an emphasis on geometric intuition and connecting various ideas that are often presented in isolation. The requisite knowledge required is familiarity with rank-nullity and hyperplanes.\nMathematical Preliminaries Let $U,W$ be two subspaces of a vector space $V$. One notion we will need is the vector space joined by combining $U$ and $V$.","keywords":[],"articleBody":"Introduction The purpose of this note is to give a rudimentary and perspicuous presentation of some foundational topics in linear algebra. There will be an emphasis on geometric intuition and connecting various ideas that are often presented in isolation. The requisite knowledge required is familiarity with rank-nullity and hyperplanes.\nMathematical Preliminaries Let $U,W$ be two subspaces of a vector space $V$. One notion we will need is the vector space joined by combining $U$ and $V$. To be precise we mean the following.\nDefinition: The sum of two vector spaces $U,W \\subset V$ is defined as the set, $U+W$, of all linear combinations that can be made from vectors in $U \\cup W$.\nWe note that $U+W$ is a subspace of $V$ as it contains $0$ and is closed under linear combinations. Two important examples are as follows.\nExample 1: First define the $x$-axis as the set, $X:=\\{(x,y) \\in \\mathbf{R}^2 : y = 0\\}$. Now the sum of $\\mathbf{R}^2$ with the $x$-axis, $\\mathbf{R}^2 + X$, is simply the entire plane $\\mathbf{R}^2$. Here we note nothing was gained by adding $X$.\nExample 2: First define the $x$-axis as the set, $X:=\\{(x,y) \\in \\mathbf{R}^2 : y = 0\\}$ and the $y$-axis as the set, $Y:=\\{(x,y) \\in \\mathbf{R}^2 : x = 0\\}$. Now observe that the sum of the $x$ and $y$ axes, $X+Y$, is the entire plane as one would expect. For full generality it is essential to remember that we can take sums of axes that are not perpendicular.\nClearly certain sums are more useful than others in their ability to “add” more vectors as occurred in Example 2. To distinguish these special sums we define the following.\nDefinition: $U+W$ is called a direct sum if every element in $U+W$ has a unique representation as the sum of an element in $U$ and an element in $W$. That is $\\mathbf{z} \\in U+W$ has unique representation $\\mathbf{z}=\\mathbf{u}+\\mathbf{w}$ where $\\mathbf{u} \\in U$ and $\\mathbf{w} \\in W$.\nWe note that the two above definitions allow us to add multiple subspaces together so statements such as $U_1+U_2+U_3$ are well-defined. In addition, the notion of direct sum in for multiple subspaces extends in the obvious way to mean unique representation as the sum of elements from each subspace.\nProjectors With the preliminaries done we can now define special kind of map known as a projector.\nDefinition: Given some direct sum $U+W = V$, we define a projector, $\\mathbf{P}: V \\to V$ as follows. Since $U+W = V$ we have any $\\mathbf{v} \\in V$ has unique representation as $\\mathbf{v} = \\mathbf{u} + \\mathbf{w}$ for some choice of $\\mathbf{u} \\in U$ and $\\mathbf{w} \\in W$. With this we define $\\mathbf{Pv} := \\mathbf{u}$.\nExercise: Prove that a projector is linear.\nExample 3: Consider the direct sum $X+Y$ from Example 2. We can define a projector that maps elements to the $X$ or $Y$ axis. This coincides with what we typically think of as projections.\nWe should point out that we can also project onto the axis of a non-perpendicular grid on the plane as well. Such an operation would also be a projector. In fact this general notion is the one to keep in mind going forward.\nRelation to Idempotence We say a function, $f$, is idempotent if $f \\circ f = f$. That is if applying the function twice is the same as applying it once. There are many examples such as the identity function or absolute value function on the real numbers.\nNow our definition of projections makes it simple to construct a projection given a direct sum. However, it may not be obvious if a given linear operator is a projection. It turns out there is a simple test to determine if a given linear operator, $\\mathbf{P}$, is a projection.\nTheorem: A linear operator, $\\mathbf{P}$, is a projection if and only if $\\mathbf{P}^2 = \\mathbf{P}$. That is $\\mathbf{P}$ is idempotent.\nWe remark that the absolute value function is not a linear map on $\\mathbf{R}$ but is idempotent. This does not contradict the above theorem because the above theorem states that any linear, idempotent operator is a projector.\nThis theorem will enable us to quickly check if an operator is a projection in later sections.\nProjection to Lines Physical Example Consider a sunny day and a lamp post standing erect on perfectly flat ground. Since the sun is sufficiently far away we assume the rays of light are parallel. The lamp post has a shadow as long as these rays of light are not parallel or perpendicular to the lamp post. The height of the shadow is determined by looking at the ray that intersects the top of the lamp post and advecting the top of the post to the ground along this ray. The advection of this point to the ground is an example of a non-orthogonal1 projector. Linear algebra is a suitable medium for modeling this phenomena as we shall soon see. Figure 1: Picture of the top of the lamp post being advected to the tip of the shadow along the ray of light (depicted in black) that intersects the top of the post.\nElementary Projectors In general, we define an elementary projector using two objects: a given real-valued linear function $\\mathbf{f}^T$, and a given vector $\\mathbf{r}$. The projection of a point $\\mathbf{z}$ is then defined in the following manner. Consider the point $\\mathbf{z}$ and the hyperplane defined by $\\mathbf{f}^T$ that it lies on. Then look at the point formed by the intersection of the foregoing hyperplane with $\\text{span}{\\mathbf{r}}$. This point of intersection is defined as the elementary projection of $\\mathbf{z}$ onto $\\text{span}{\\mathbf{r}}$ given $\\mathbf{f}^T$. This process can be viewed as advecting $\\mathbf{z}$ along the line segment connecting it to $\\text{span}{\\mathbf{r}}$ which lies wholly in a level set of $\\mathbf{f}^T$.\nIn our physical analogy level sets of $\\mathbf{f}^T$ correspond to rays of light and the floor corresponds to $\\text{span} {\\mathbf{r}}$.\nWe deduce a mathematical formula by exploiting two critical facts: the projection is equal to $\\lambda \\mathbf{r}$ for appropriate scalar $\\lambda$, and the projection and $\\mathbf{z}$ lie in the same level set of $\\mathbf{f}^T$. Thus $\\lambda = \\frac{\\mathbf{f}^{T}\\mathbf{z}}{\\mathbf{f}^T\\mathbf{r}}$. Therefore our resulting projection is,\n$$\\frac{\\mathbf{r}\\mathbf{f}^{T}}{\\mathbf{f}^T\\mathbf{r}} \\mathbf{z}.$$\nWe note in our derivation we assumed that $\\mathbf{f}^{T}$ intersects $\\mathbf{r}$ at a unique point. This is equivalent to assuming $\\mathbf{f}^{T}\\mathbf{r} \\neq 0$ which makes our expression well defined. Given the derivation we can summarize our findings with the following.\nDefinition: We say an operator $\\mathbf{P}$ is an elementary projector if $\\mathbf{P} = \\frac{\\mathbf{r}\\mathbf{f}^{T}}{\\mathbf{f}^T\\mathbf{r}}$.\nWe can verify this is in fact a projector by calculating $\\mathbf{P}^2$ and observing the $\\mathbf{P}$ is idempotent. Thus our elementary projector is a projector as expected.\nWe note an equivalent definition of elementary projector is the following.\nDefinition: Given a direct sum $U+W = V$, we define a projector $\\mathbf{P}$ exactly as before. If $U$ is one dimensional then we call $\\mathbf{P}$ an elementary projector.\nBoth definitions of an elementary projector are equivalent, however the first gives us a formula and method to compute an elementary projector. For clarity and completeness we demonstrate a proof that these are equivalent.\nTheorem: Every projector, $\\mathbf{P}$, onto a one dimensional subspace can be written as $\\frac{\\mathbf{r}\\mathbf{f}^{T}}{\\mathbf{f}^T\\mathbf{r}}$\nElementary Orthogonal Projections It is common to restrict discussion of elementary projections to those that are orthogonal. That is the level sets of $\\mathbf{r}^T$ are perpendicular to $\\mathbf{c}$. If our coordinate system consists of basis of orthonormal vectors(as is almost always the case in applications) then the transpose of $c$ is the appropriate choice of $\\mathbf{r}^T$. This process corresponds to projection of a point onto a line in a coordinate system consisting of straight, perpendicular axes such as the Cartesian plane. Think “dropping a perpendicular”.\nExample 1: $2 \\times 2$ Matrix Inverse Given a matrix, $$ M = \\begin{bmatrix}a \u0026 b \\newline c \u0026 d\\end{bmatrix} = \\begin{bmatrix} \\vert \u0026 \\vert \\newline p \u0026 q \\newline \\vert \u0026 \\vert \\end{bmatrix}, $$ it is well-known that the inverse matrix is, $$ M^{-1} = \\frac{1}{ad-bc}\\begin{bmatrix}d \u0026 -b \\newline -c \u0026 a\\end{bmatrix}. $$ Figure 1: The orange and green lines correspond to the $p$ and $q$ axes, respectively. Their intersection is the origin and the light blue point denotes the projection onto $\\text{span }p$\nViewing the matrix, $M$, as a change of coordinates leads to a perspicuous derivation of the inverse. $M$ takes coordinates from the $pq$ grid and changes them to coordinates of the $xy$ grid. Hence, the inverse should be the matrix that transforms $xy$ coordinates $pq$ coordinates. Moving a point written in $xy$ coordinates onto the line $\\text{span }p$ geometrically corresponds to translating the point along lines parallel to $\\text{span }q$ until it intersects $\\text{span }p$. This is exactly an elementary projection where $r = p$ and $f^T$ has level sets parallel to $\\text{span }q$. To determine $f^T$ precisely can be identified with a $1 \\times 2$ matrix that sends $\\text{span } q$ to $0$. One can arrive at $f^T = \\begin{bmatrix} d \u0026 -b\\end{bmatrix}$ by guessing or by rotating $q$ ninety degrees counterclockwise . Thus we conclude, $$ \\frac{f^{T}}{f^Tr} = \\frac{1}{ad-bc} \\begin{bmatrix} d \u0026 -b \\end{bmatrix}, $$ is the operator we need to apply to $xy$ coordinates to find the $p$-coordinate in our $pq$ grid. This is exactly the first row of our inverse matrix above. The second row can be derived using the same methodology as above except interchanging the role of $p$ and $q$.\nThis method generalizes to higher dimensions so we can understand how to geometrically derive inverses of matrices in all cases. However, it becomes tricky to determine $\\mathbf{f}^T$ in higher dimensions. The cleanest method would be to use the determinant to derive the appropriate $\\mathbf{f}^T$. Do you see how? This should also give complete geometric meaning to the adjugate matrix which is typically defined using cofactors and algebraic chicanery that obscures its geometric essence.\nExample 2: Stereographic Projection Stereographic projection is a mapping from the unit sphere in 3d space to the $xy$ plane that often arises in complex analysis. The mapping is defined as follows. For any point on the sphere draw the line intersecting the north pole and the foregoing sphere; the intersection of this line and the $xy$ plane is stereographic projection of the point. The north pole is the only point on the sphere for which we cannot define its stereographic projection. If we restrict to only looking at the plane containing the origin, $P$, and $N$ we see this operation can be described by an elementary projector. Let $\\mathbf{r}$ correspond to horizontal axis and let $\\mathbf{f}^T$ have level sets parallel to the line between the North Pole and $P$. That is use the North Pole and $P$ to deduce $\\mathbf{f}^T$. The elementary projector is determined one can deduce the $x$ and $y$ components in the plane using basic trigonometry.\nProjections to Vector Spaces Big Theorem: Decomposition Up until now we have only considered the simplest projectors and basic applications. A generic projector can have $\\text{dim }U \u003e 1$. These may seem more complicated however we have the following decomposition.\nTheorem: Every projector $\\mathbf{P}$ can be decomposed into a sum of pairwise, mutually annihilating elementary projectors. That is $\\mathbf{P} = \\mathbf{P}_1 + \\mathbf{P_2} + \\ldots + \\mathbf{P}_m$ where $\\mathbf{P}_i\\mathbf{P}_j = 0$ if $i \\neq j$.\nLet $U + W = V$ be the direct sum such that $\\mathbf{P}\\mathbf{z} = \\mathbf{P}(\\mathbf{u}+\\mathbf{w}) = \\mathbf{u}$ where $\\mathbf{u} \\in U$ and $\\mathbf{w} \\in W$. Consider $\\mathbf{u}_1, \\mathbf{u}_2, \\ldots, \\mathbf{u}_m$ to be a basis for $U$. Then given the direct sum $\\text{span } \\mathbf{u}_i + (( \\cup_{j \\neq i} \\mathbf{u}_j ) \\cup W )$ define the elementary projector, $\\mathbf{P}_i$, which maps onto $\\text{span }\\mathbf{u}_i $. From our definitions we have that $\\mathbf{P} = \\mathbf{P}_1 + \\ldots + \\mathbf{P}_m$. The various $\\mathbf{P}_i$ are also mutually annihilating(i.e. $\\mathbf{P}_i\\mathbf{P}_j = 0$ if $ i \\neq j$) which is easily verified.\nExample 1: Least Squares Example 2: Quantum Mechanics Example 3: Cross Products Connection to Spectral Theory Been boop\nConnection to Optimization We are often in situations where we are given a norm. That is we are given a way to measure lengths in the space. Many optimization problems consist of\nReflectors We will mimic the development done for projectors to develop the theory of reflectors.\nDefinition: Given some direct sum $U+W = V$, we define a reflector, $\\mathbf{R}: V \\to V$ as follows. Since $U+W = V$ we have any $\\mathbf{v} \\in V$ has unique representation as $\\mathbf{v} = \\mathbf{u} + \\mathbf{w}$ for some choice of $\\mathbf{u} \\in U$ and $\\mathbf{w} \\in W$. With this we define $\\mathbf{Rv} := \\mathbf{u} - \\mathbf{w}$.\nExercise: Prove that a reflector is linear.\nExample 3: Consider the direct sum $X+Y$ from Example 2. We can define a reflector that reflects over the $X$ or $Y$ axis. This coincides with what we typically think of as reflection.\nRelation to Projections It turns out reflectors and projectors are intimately related. When we reflect a point in the plane over the $x$-axis, we could explicitly do this in 2 steps. We could first project the point onto the $y$-axis. Then we subtract twice the projection onto the $y$-axis from the original point. It turns out this method using projectors to build reflectors is more general. We sum this up as follows.\nTheorem: Every reflector $\\mathbf{R}$ can be expressed $\\mathbf{R} = \\mathbf{I} - 2\\mathbf{P}$ where $\\mathbf{P}$ is some appropriate choice of projector.\nGiven the direct sum $U+W$ corresponding to the reflector $\\mathbf{R}$ we define the projector $\\mathbf{P}_W \\mathbf{z} = \\mathbf{P}_W (\\mathbf{u} + \\mathbf{w}) = \\mathbf{w}$. From this it follows that $\\mathbf{R} = \\mathbf{I} - 2\\mathbf{P}_W$.\nRelation to Involution We say a function, $f$, is an involution if $(f \\circ f)(x) = x$. That is if applying the function twice is the same as applying the identity. There are many examples such as taking reciprocals, multiplying by $-1$, or complex conjugation.\nNow our definition of reflectors makes it simple to construct a reflector given a direct sum. However, it may not be obvious if a given linear operator is a reflector. It turns out there is a simple test to determine if a given linear operator, $\\mathbf{R}$, is a reflector.\nTheorem: A linear operator, $\\mathbf{R}$, is a reflector if and only if $\\mathbf{R}^2 = \\mathbf{I}$. That is $\\mathbf{R}$ is involution.\nProving the necessity of involution is a straightforward exercise. Do you see why? However proving that if a linear operator, $\\mathbf{R}$ satisfies $\\mathbf{R}^2 = \\mathbf{I}$ then it is a reflection is more difficult. We invoke the relation to projection to note\nReflection Over Hyperplanes Physical Example Elementary Reflectors Elementary Orthogonal Reflectors (Householder Transformations) Complex Conjugation Reflection Over Subspaces Big Theorem: Decomposition Dilators Elementary Dilator When Is An Operator A Dilator? Gaussian Elimination Non-orthogonal refers to the fact that the ray connecting the tips of the shadow and post does not form a right angle with the ground. ↩︎\n","wordCount":"2458","inLanguage":"en","datePublished":"2023-03-09T00:00:00Z","dateModified":"2023-03-09T00:00:00Z","author":{"@type":"Person","name":"Aman Shah"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://amanshah2711.github.io/paper-blog/posts/projections/"},"publisher":{"@type":"Organization","name":"Parallelogram","logo":{"@type":"ImageObject","url":"https://amanshah2711.github.io/paper-blog/%3Clink%20/%20abs%20url%3E"}}}</script></head><body id=top><header class=header><nav class=nav><div class=logo><a href=https://amanshah2711.github.io/paper-blog/ accesskey=h title="Parallelogram (Alt + H)"><img src=https://amanshah2711.github.io/apple-touch-icon.png alt aria-label=logo height=35>Parallelogram</a><div class=logo-switches></div></div><ul id=menu><li><a href=https://amanshah2711.github.io/paper-blog/posts/ title=posts><span>posts</span></a></li><li><a href=https://amanshah2711.github.io/paper-blog/search/ title="search (Alt + /)" accesskey=/><span>search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class=post-title>Geometry of Linear Operators</h1><div class=post-meta><span title='2023-03-09 00:00:00 +0000 UTC'>March 9, 2023</span>&nbsp;·&nbsp;Aman Shah&nbsp;|&nbsp;<a href=https://github.com/amanshah2711/paper-blog/tree/main/content/posts/projections/index.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#introduction>Introduction</a></li><li><a href=#mathematical-preliminaries>Mathematical Preliminaries</a></li><li><a href=#projectors>Projectors</a><ul><li><a href=#relation-to-idempotence>Relation to Idempotence</a></li><li><a href=#projection-to-lines>Projection to Lines</a><ul><li><a href=#physical-example>Physical Example</a></li><li><a href=#elementary-projectors>Elementary Projectors</a></li><li><a href=#elementary-orthogonal-projections>Elementary Orthogonal Projections</a></li><li><a href=#example-1-2-times-2-matrix-inverse>Example 1: $2 \times 2$ Matrix Inverse</a></li><li><a href=#example-2-stereographic-projection>Example 2: Stereographic Projection</a></li></ul></li><li><a href=#projections-to-vector-spaces>Projections to Vector Spaces</a><ul><li><a href=#big-theorem-decomposition>Big Theorem: Decomposition</a></li><li><a href=#example-1-least-squares>Example 1: Least Squares</a></li><li><a href=#example-2-quantum-mechanics>Example 2: Quantum Mechanics</a></li><li><a href=#example-3-cross-products>Example 3: Cross Products</a></li></ul></li><li><a href=#connection-to-spectral-theory>Connection to Spectral Theory</a></li><li><a href=#connection-to-optimization>Connection to Optimization</a></li></ul></li><li><a href=#reflectors>Reflectors</a><ul><li><a href=#relation-to-projections>Relation to Projections</a></li><li><a href=#relation-to-involution>Relation to Involution</a></li><li><a href=#reflection-over-hyperplanes>Reflection Over Hyperplanes</a><ul><li><a href=#physical-example-1>Physical Example</a></li><li><a href=#elementary-reflectors>Elementary Reflectors</a></li><li><a href=#elementary-orthogonal-reflectors-householder-transformations>Elementary Orthogonal Reflectors (Householder Transformations)</a></li><li><a href=#complex-conjugation>Complex Conjugation</a></li></ul></li><li><a href=#reflection-over-subspaces>Reflection Over Subspaces</a><ul><li><a href=#big-theorem-decomposition-1>Big Theorem: Decomposition</a></li></ul></li></ul></li><li><a href=#dilators>Dilators</a><ul><li><a href=#elementary-dilator>Elementary Dilator</a></li><li><a href=#when-is-an-operator-a-dilator>When Is An Operator A Dilator?</a></li></ul></li><li><a href=#gaussian-elimination>Gaussian Elimination</a></li></ul></nav></div></details></div><div class=post-content><h2 id=introduction>Introduction<a hidden class=anchor aria-hidden=true href=#introduction>#</a></h2><p>The purpose of this note is to give a rudimentary and perspicuous presentation of some foundational topics in linear algebra. There will be an emphasis on geometric intuition and connecting various ideas that are often presented in isolation. The requisite knowledge required is familiarity with rank-nullity and <a href>hyperplanes</a>.</p><h2 id=mathematical-preliminaries>Mathematical Preliminaries<a hidden class=anchor aria-hidden=true href=#mathematical-preliminaries>#</a></h2><p>Let $U,W$ be two subspaces of a vector space $V$. One notion we will need is the vector space joined by combining $U$ and $V$. To be precise we mean the following.</p><blockquote><p><strong>Definition:</strong> The sum of two vector spaces $U,W \subset V$ is defined as the set, $U+W$, of all linear combinations that can be made from vectors in $U \cup W$.</p></blockquote><p>We note that $U+W$ is a subspace of $V$ as it contains $0$ and is closed under linear combinations. Two important examples are as follows.</p><blockquote><p><strong>Example 1:</strong> First define the $x$-axis as the set, $X:=\{(x,y) \in \mathbf{R}^2 : y = 0\}$. Now the sum of $\mathbf{R}^2$ with the $x$-axis, $\mathbf{R}^2 + X$, is simply the entire plane $\mathbf{R}^2$. Here we note nothing was gained by adding $X$.</p></blockquote><blockquote><p><strong>Example 2:</strong> First define the $x$-axis as the set, $X:=\{(x,y) \in \mathbf{R}^2 : y = 0\}$ and the $y$-axis as the set, $Y:=\{(x,y) \in \mathbf{R}^2 : x = 0\}$. Now observe that the sum of the $x$ and $y$ axes, $X+Y$, is the entire plane as one would expect. For full generality it is essential to remember that we can take sums of axes that are not perpendicular.</p></blockquote><p>Clearly certain sums are more useful than others in their ability to &ldquo;add&rdquo; more vectors as occurred in Example 2. To distinguish these special sums we define the following.</p><blockquote><p><strong>Definition:</strong> $U+W$ is called a <strong>direct sum</strong> if every element in $U+W$ has a unique representation as the sum of an element in $U$ and an element in $W$. That is $\mathbf{z} \in U+W$ has unique representation $\mathbf{z}=\mathbf{u}+\mathbf{w}$ where $\mathbf{u} \in U$ and $\mathbf{w} \in W$.</p></blockquote><p>We note that the two above definitions allow us to add multiple subspaces together so statements such as $U_1+U_2+U_3$ are well-defined. In addition, the notion of direct sum in for multiple subspaces extends in the obvious way to mean unique representation as the sum of elements from each subspace.</p><h2 id=projectors>Projectors<a hidden class=anchor aria-hidden=true href=#projectors>#</a></h2><p>With the preliminaries done we can now define special kind of map known as a projector.</p><blockquote><p><strong>Definition:</strong> Given some direct sum $U+W = V$, we define a <strong>projector</strong>, $\mathbf{P}: V \to V$ as follows. Since $U+W = V$ we have any $\mathbf{v} \in V$ has unique representation as $\mathbf{v} = \mathbf{u} + \mathbf{w}$ for some choice of $\mathbf{u} \in U$ and $\mathbf{w} \in W$. With this we define $\mathbf{Pv} := \mathbf{u}$.</p></blockquote><p><em>Exercise: Prove that a projector is linear.</em></p><blockquote><p><strong>Example 3:</strong> Consider the direct sum $X+Y$ from Example 2. We can define a projector that maps elements to the $X$ or $Y$ axis. This coincides with what we typically think of as projections.</p></blockquote><p>We should point out that we can also project onto the axis of a non-perpendicular grid on the plane as well. Such an operation would also be a projector. In fact this general notion is the one to keep in mind going forward.</p><h3 id=relation-to-idempotence>Relation to Idempotence<a hidden class=anchor aria-hidden=true href=#relation-to-idempotence>#</a></h3><p>We say a function, $f$, is <strong>idempotent</strong> if $f \circ f = f$. That is if applying the function twice is the same as applying it once. There are many examples such as the identity function or absolute value function on the real numbers.</p><p>Now our definition of projections makes it simple to construct a projection given a direct sum. However, it may not be obvious if a given linear operator is a projection. It turns out there is a simple test to determine if a given linear operator, $\mathbf{P}$, is a projection.</p><blockquote><p><strong>Theorem:</strong> A linear operator, $\mathbf{P}$, is a projection if and only if $\mathbf{P}^2 = \mathbf{P}$. That is $\mathbf{P}$ is idempotent.</p></blockquote><p>We remark that the absolute value function is not a linear map on $\mathbf{R}$ but is idempotent. This does not contradict the above theorem because the above theorem states that any <em>linear</em>, idempotent operator is a projector.</p><p>This theorem will enable us to quickly check if an operator is a projection in later sections.</p><h3 id=projection-to-lines>Projection to Lines<a hidden class=anchor aria-hidden=true href=#projection-to-lines>#</a></h3><h4 id=physical-example>Physical Example<a hidden class=anchor aria-hidden=true href=#physical-example>#</a></h4><p>Consider a sunny day and a lamp post standing erect on perfectly flat ground. Since the sun is sufficiently far away we assume the rays of light are parallel. The lamp post has a shadow as long as these rays of light are not parallel or perpendicular to the lamp post. The height of the shadow is determined by looking at the ray that intersects the top of the lamp post and advecting the top of the post to the ground along this ray. The advection of this point to the ground is an example of a non-orthogonal<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup> projector. Linear algebra is a suitable medium for modeling this phenomena as we shall soon see.
<img loading=lazy src=images/lamppost.png#center alt="Visual of physical example">
<em>Figure 1: Picture of the top of the lamp post being advected to the tip of the shadow along the ray of light (depicted in black) that intersects the top of the post.</em></p><h4 id=elementary-projectors>Elementary Projectors<a hidden class=anchor aria-hidden=true href=#elementary-projectors>#</a></h4><p>In general, we define an elementary projector using two objects: a given real-valued linear function $\mathbf{f}^T$, and a given vector $\mathbf{r}$. The projection of a point $\mathbf{z}$ is then defined in the following manner. Consider the point $\mathbf{z}$ and the hyperplane defined by $\mathbf{f}^T$ that it lies on. Then look at the point formed by the intersection of the foregoing hyperplane with $\text{span}{\mathbf{r}}$. This point of intersection is defined as the elementary projection of $\mathbf{z}$ onto $\text{span}{\mathbf{r}}$ given $\mathbf{f}^T$. This process can be viewed as advecting $\mathbf{z}$ along the line segment connecting it to $\text{span}{\mathbf{r}}$ which lies wholly in a level set of $\mathbf{f}^T$.</p><p>In our physical analogy level sets of $\mathbf{f}^T$ correspond to rays of light and the floor corresponds to $\text{span} {\mathbf{r}}$.</p><p>We deduce a mathematical formula by exploiting two critical facts: the projection is equal to $\lambda \mathbf{r}$ for appropriate scalar $\lambda$, and the projection and $\mathbf{z}$ lie in the same level set of $\mathbf{f}^T$. Thus $\lambda = \frac{\mathbf{f}^{T}\mathbf{z}}{\mathbf{f}^T\mathbf{r}}$. Therefore our resulting projection is,</p><p>$$\frac{\mathbf{r}\mathbf{f}^{T}}{\mathbf{f}^T\mathbf{r}} \mathbf{z}.$$</p><p>We note in our derivation we assumed that $\mathbf{f}^{T}$ intersects $\mathbf{r}$ at a unique point. This is equivalent to assuming $\mathbf{f}^{T}\mathbf{r} \neq 0$ which makes our expression well defined. Given the derivation we can summarize our findings with the following.</p><blockquote><p><strong>Definition:</strong> We say an operator $\mathbf{P}$ is an <strong>elementary projector</strong> if $\mathbf{P} = \frac{\mathbf{r}\mathbf{f}^{T}}{\mathbf{f}^T\mathbf{r}}$.</p></blockquote><p>We can verify this is in fact a projector by calculating $\mathbf{P}^2$ and observing the $\mathbf{P}$ is idempotent. Thus our elementary projector is a projector as expected.</p><p>We note an equivalent definition of elementary projector is the following.</p><blockquote><p><strong>Definition:</strong> Given a direct sum $U+W = V$, we define a projector $\mathbf{P}$ exactly as before. If $U$ is one dimensional then we call $\mathbf{P}$ an <strong>elementary projector</strong>.</p></blockquote><p>Both definitions of an elementary projector are equivalent, however the first gives us a formula and method to compute an elementary projector. For clarity and completeness we demonstrate a proof that these are equivalent.</p><blockquote><p><strong>Theorem:</strong> Every projector, $\mathbf{P}$, onto a one dimensional subspace can be written as $\frac{\mathbf{r}\mathbf{f}^{T}}{\mathbf{f}^T\mathbf{r}}$</p></blockquote><h4 id=elementary-orthogonal-projections>Elementary Orthogonal Projections<a hidden class=anchor aria-hidden=true href=#elementary-orthogonal-projections>#</a></h4><p>It is common to restrict discussion of elementary projections to those that are orthogonal. That is the level sets of $\mathbf{r}^T$ are perpendicular to $\mathbf{c}$. If our coordinate system consists of basis of orthonormal vectors(as is almost always the case in applications) then the transpose of $c$ is the appropriate choice of $\mathbf{r}^T$. This process corresponds to projection of a point onto a line in a coordinate system consisting of straight, perpendicular axes such as the Cartesian plane. Think &ldquo;dropping a perpendicular&rdquo;.</p><h4 id=example-1-2-times-2-matrix-inverse>Example 1: $2 \times 2$ Matrix Inverse<a hidden class=anchor aria-hidden=true href=#example-1-2-times-2-matrix-inverse>#</a></h4><p>Given a matrix,
$$
M = \begin{bmatrix}a & b \newline c & d\end{bmatrix} = \begin{bmatrix}
\vert & \vert \newline
p & q \newline
\vert & \vert
\end{bmatrix},
$$
it is well-known that the inverse matrix is,
$$
M^{-1} = \frac{1}{ad-bc}\begin{bmatrix}d & -b \newline -c & a\end{bmatrix}.
$$
<img loading=lazy src=images/projection.png#center alt="Visual of change of coordinates">
<em>Figure 1: The orange and green lines correspond to the $p$ and $q$ axes, respectively. Their intersection is the origin and the light blue point denotes the projection onto $\text{span }p$</em></p><p>Viewing the matrix, $M$, as a change of coordinates leads to a perspicuous derivation of the inverse. $M$ takes coordinates from the $pq$ grid and changes them to coordinates of the $xy$ grid. Hence, the inverse should be the matrix that transforms $xy$ coordinates $pq$ coordinates. Moving a point written in $xy$ coordinates onto the line $\text{span }p$ geometrically corresponds to translating the point along lines parallel to $\text{span }q$ until it intersects $\text{span }p$. This is exactly an elementary projection where $r = p$ and $f^T$ has level sets parallel to $\text{span }q$. To determine $f^T$ precisely can be identified with a $1 \times 2$ matrix that sends $\text{span } q$ to $0$. One can arrive at $f^T = \begin{bmatrix} d & -b\end{bmatrix}$ by guessing or by rotating $q$ ninety degrees counterclockwise . Thus we conclude,
$$
\frac{f^{T}}{f^Tr} = \frac{1}{ad-bc} \begin{bmatrix} d & -b \end{bmatrix},
$$
is the operator we need to apply to $xy$ coordinates to find the $p$-coordinate in our $pq$ grid. This is exactly the first row of our inverse matrix above. The second row can be derived using the same methodology as above except interchanging the role of $p$ and $q$.</p><p>This method generalizes to higher dimensions so we can understand how to geometrically derive inverses of matrices in all cases. However, it becomes tricky to determine $\mathbf{f}^T$ in higher dimensions. The cleanest method would be to use the determinant to derive the appropriate $\mathbf{f}^T$. Do you see how? This should also give complete geometric meaning to the <a href=https://en.wikipedia.org/wiki/Adjugate_matrix>adjugate matrix</a> which is typically defined using cofactors and algebraic chicanery that obscures its geometric essence.</p><h4 id=example-2-stereographic-projection>Example 2: Stereographic Projection<a hidden class=anchor aria-hidden=true href=#example-2-stereographic-projection>#</a></h4><p>Stereographic projection is a mapping from the unit sphere in 3d space to the $xy$ plane that often arises in complex analysis. The mapping is defined as follows. For any point on the sphere draw the line intersecting the north pole and the foregoing sphere; the intersection of this line and the $xy$ plane is stereographic projection of the point. The north pole is the only point on the sphere for which we cannot define its stereographic projection.
<img loading=lazy src=images/stereographic.png#center alt="Visual of stereographic projection">
If we restrict to only looking at the plane containing the origin, $P$, and $N$ we see this operation can be described by an elementary projector. Let $\mathbf{r}$ correspond to horizontal axis and let $\mathbf{f}^T$ have level sets parallel to the line between the North Pole and $P$. That is use the North Pole and $P$ to deduce $\mathbf{f}^T$. The elementary projector is determined one can deduce the $x$ and $y$ components in the plane using basic trigonometry.</p><h3 id=projections-to-vector-spaces>Projections to Vector Spaces<a hidden class=anchor aria-hidden=true href=#projections-to-vector-spaces>#</a></h3><h4 id=big-theorem-decomposition>Big Theorem: Decomposition<a hidden class=anchor aria-hidden=true href=#big-theorem-decomposition>#</a></h4><p>Up until now we have only considered the simplest projectors and basic applications. A generic projector can have $\text{dim }U > 1$. These may seem more complicated however we have the following decomposition.</p><blockquote><p><strong>Theorem:</strong> Every projector $\mathbf{P}$ can be decomposed into a sum of pairwise, mutually annihilating elementary projectors. That is $\mathbf{P} = \mathbf{P}_1 + \mathbf{P_2} + \ldots + \mathbf{P}_m$ where $\mathbf{P}_i\mathbf{P}_j = 0$ if $i \neq j$.</p></blockquote><p>Let $U + W = V$ be the direct sum such that $\mathbf{P}\mathbf{z} = \mathbf{P}(\mathbf{u}+\mathbf{w}) = \mathbf{u}$ where $\mathbf{u} \in U$ and $\mathbf{w} \in W$. Consider $\mathbf{u}_1, \mathbf{u}_2, \ldots, \mathbf{u}_m$ to be a basis for $U$. Then given the direct sum $\text{span } \mathbf{u}_i + (( \cup_{j \neq i} \mathbf{u}_j ) \cup W )$ define the elementary projector, $\mathbf{P}_i$, which maps onto $\text{span }\mathbf{u}_i $. From our definitions we have that $\mathbf{P} = \mathbf{P}_1 + \ldots + \mathbf{P}_m$. The various $\mathbf{P}_i$ are also mutually annihilating(i.e. $\mathbf{P}_i\mathbf{P}_j = 0$ if $ i \neq j$) which is easily verified.</p><h4 id=example-1-least-squares>Example 1: Least Squares<a hidden class=anchor aria-hidden=true href=#example-1-least-squares>#</a></h4><h4 id=example-2-quantum-mechanics>Example 2: Quantum Mechanics<a hidden class=anchor aria-hidden=true href=#example-2-quantum-mechanics>#</a></h4><h4 id=example-3-cross-products>Example 3: Cross Products<a hidden class=anchor aria-hidden=true href=#example-3-cross-products>#</a></h4><h3 id=connection-to-spectral-theory>Connection to Spectral Theory<a hidden class=anchor aria-hidden=true href=#connection-to-spectral-theory>#</a></h3><p>Been boop</p><h3 id=connection-to-optimization>Connection to Optimization<a hidden class=anchor aria-hidden=true href=#connection-to-optimization>#</a></h3><p>We are often in situations where we are given a norm. That is we are given a way to measure lengths in the space. Many optimization problems consist of</p><h2 id=reflectors>Reflectors<a hidden class=anchor aria-hidden=true href=#reflectors>#</a></h2><p>We will mimic the development done for projectors to develop the theory of reflectors.</p><blockquote><p><strong>Definition:</strong> Given some direct sum $U+W = V$, we define a <strong>reflector</strong>, $\mathbf{R}: V \to V$ as follows. Since $U+W = V$ we have any $\mathbf{v} \in V$ has unique representation as $\mathbf{v} = \mathbf{u} + \mathbf{w}$ for some choice of $\mathbf{u} \in U$ and $\mathbf{w} \in W$. With this we define $\mathbf{Rv} := \mathbf{u} - \mathbf{w}$.</p></blockquote><p><em>Exercise: Prove that a reflector is linear.</em></p><blockquote><p><strong>Example 3:</strong> Consider the direct sum $X+Y$ from Example 2. We can define a reflector that reflects over the $X$ or $Y$ axis. This coincides with what we typically think of as reflection.</p></blockquote><h3 id=relation-to-projections>Relation to Projections<a hidden class=anchor aria-hidden=true href=#relation-to-projections>#</a></h3><p>It turns out reflectors and projectors are intimately related. When we reflect a point in the plane over the $x$-axis, we could explicitly do this in 2 steps. We could first project the point onto the $y$-axis. Then we subtract twice the projection onto the $y$-axis from the original point. It turns out this method using projectors to build reflectors is more general. We sum this up as follows.</p><blockquote><p><strong>Theorem:</strong> Every reflector $\mathbf{R}$ can be expressed $\mathbf{R} = \mathbf{I} - 2\mathbf{P}$ where $\mathbf{P}$ is some appropriate choice of projector.</p></blockquote><p>Given the direct sum $U+W$ corresponding to the reflector $\mathbf{R}$ we define the projector $\mathbf{P}_W \mathbf{z} = \mathbf{P}_W (\mathbf{u} + \mathbf{w}) = \mathbf{w}$. From this it follows that $\mathbf{R} = \mathbf{I} - 2\mathbf{P}_W$.</p><h3 id=relation-to-involution>Relation to Involution<a hidden class=anchor aria-hidden=true href=#relation-to-involution>#</a></h3><p>We say a function, $f$, is an <strong>involution</strong> if $(f \circ f)(x) = x$. That is if applying the function twice is the same as applying the identity. There are many examples such as taking reciprocals, multiplying by $-1$, or complex conjugation.</p><p>Now our definition of reflectors makes it simple to construct a reflector given a direct sum. However, it may not be obvious if a given linear operator is a reflector. It turns out there is a simple test to determine if a given linear operator, $\mathbf{R}$, is a reflector.</p><blockquote><p><strong>Theorem:</strong> A linear operator, $\mathbf{R}$, is a reflector if and only if $\mathbf{R}^2 = \mathbf{I}$. That is $\mathbf{R}$ is involution.</p></blockquote><p>Proving the necessity of involution is a straightforward exercise. Do you see why? However proving that if a linear operator, $\mathbf{R}$ satisfies $\mathbf{R}^2 = \mathbf{I}$ then it is a reflection is more difficult. We invoke the relation to projection to note</p><h3 id=reflection-over-hyperplanes>Reflection Over Hyperplanes<a hidden class=anchor aria-hidden=true href=#reflection-over-hyperplanes>#</a></h3><h4 id=physical-example-1>Physical Example<a hidden class=anchor aria-hidden=true href=#physical-example-1>#</a></h4><h4 id=elementary-reflectors>Elementary Reflectors<a hidden class=anchor aria-hidden=true href=#elementary-reflectors>#</a></h4><h4 id=elementary-orthogonal-reflectors-householder-transformations>Elementary Orthogonal Reflectors (Householder Transformations)<a hidden class=anchor aria-hidden=true href=#elementary-orthogonal-reflectors-householder-transformations>#</a></h4><h4 id=complex-conjugation>Complex Conjugation<a hidden class=anchor aria-hidden=true href=#complex-conjugation>#</a></h4><h3 id=reflection-over-subspaces>Reflection Over Subspaces<a hidden class=anchor aria-hidden=true href=#reflection-over-subspaces>#</a></h3><h4 id=big-theorem-decomposition-1>Big Theorem: Decomposition<a hidden class=anchor aria-hidden=true href=#big-theorem-decomposition-1>#</a></h4><h2 id=dilators>Dilators<a hidden class=anchor aria-hidden=true href=#dilators>#</a></h2><h3 id=elementary-dilator>Elementary Dilator<a hidden class=anchor aria-hidden=true href=#elementary-dilator>#</a></h3><h3 id=when-is-an-operator-a-dilator>When Is An Operator A Dilator?<a hidden class=anchor aria-hidden=true href=#when-is-an-operator-a-dilator>#</a></h3><h2 id=gaussian-elimination>Gaussian Elimination<a hidden class=anchor aria-hidden=true href=#gaussian-elimination>#</a></h2><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p>Non-orthogonal refers to the fact that the ray connecting the tips of the shadow and post does not form a right angle with the ground.&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></div><footer class=post-footer><ul class=post-tags></ul><div class=share-buttons><a target=_blank rel="noopener noreferrer" aria-label="share Geometry of Linear Operators on twitter" href="https://twitter.com/intent/tweet/?text=Geometry%20of%20Linear%20Operators&amp;url=https%3a%2f%2famanshah2711.github.io%2fpaper-blog%2fposts%2fprojections%2f&amp;hashtags="><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Geometry of Linear Operators on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2famanshah2711.github.io%2fpaper-blog%2fposts%2fprojections%2f&amp;title=Geometry%20of%20Linear%20Operators&amp;summary=Geometry%20of%20Linear%20Operators&amp;source=https%3a%2f%2famanshah2711.github.io%2fpaper-blog%2fposts%2fprojections%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Geometry of Linear Operators on reddit" href="https://reddit.com/submit?url=https%3a%2f%2famanshah2711.github.io%2fpaper-blog%2fposts%2fprojections%2f&title=Geometry%20of%20Linear%20Operators"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Geometry of Linear Operators on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2famanshah2711.github.io%2fpaper-blog%2fposts%2fprojections%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Geometry of Linear Operators on whatsapp" href="https://api.whatsapp.com/send?text=Geometry%20of%20Linear%20Operators%20-%20https%3a%2f%2famanshah2711.github.io%2fpaper-blog%2fposts%2fprojections%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Geometry of Linear Operators on telegram" href="https://telegram.me/share/url?text=Geometry%20of%20Linear%20Operators&amp;url=https%3a%2f%2famanshah2711.github.io%2fpaper-blog%2fposts%2fprojections%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></div></footer></article></main><footer class=footer><span>&copy; 2024 <a href=https://amanshah2711.github.io/paper-blog/>Parallelogram</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>